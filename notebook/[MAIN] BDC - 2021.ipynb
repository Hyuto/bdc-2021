{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# BDC - Satria Data 2021\n\nTask : Gender Detection\n\n## Authors\n\n1. Muhammad Amanda\n2. Naufal Zhafran A.\n3. Wahyu Setianto\n\n## Running On\n\nKaggle [using GPU]","metadata":{}},{"cell_type":"markdown","source":"## First Thing First\n\nMenginstall library yang diperlukan dan mengimport library - library yang akan digunakan serta menseting variable config yang akan digunakan di dalam notebook ini.","metadata":{}},{"cell_type":"markdown","source":"1. Menginstal library`MTCNN`\n\nLibrary `MTCNN` adalah library yang digunakan untuk preprocessing data gambar pada notebook ini","metadata":{}},{"cell_type":"code","source":"!pip -q install mtcnn","metadata":{"execution":{"iopub.status.busy":"2021-10-28T15:38:46.963061Z","iopub.execute_input":"2021-10-28T15:38:46.963826Z","iopub.status.idle":"2021-10-28T15:38:56.643562Z","shell.execute_reply.started":"2021-10-28T15:38:46.963728Z","shell.execute_reply":"2021-10-28T15:38:56.642735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"2. Importing library\n\nMengimport library yang akan digunakan dalam notebook ini.","metadata":{}},{"cell_type":"code","source":"# Umum\nimport os, random\nfrom tqdm.notebook import tqdm\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\n\n# Tensorflow\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\n\n# Metrics & Splitting data\nfrom sklearn.metrics import *\nfrom sklearn.model_selection import *\n\n# Plotting\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Preprocessing\nimport cv2\nfrom mtcnn import MTCNN\n\nprint(\"Tensorflow :\", tf.__version__)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-28T15:38:58.258917Z","iopub.execute_input":"2021-10-28T15:38:58.25973Z","iopub.status.idle":"2021-10-28T15:39:04.164075Z","shell.execute_reply.started":"2021-10-28T15:38:58.259692Z","shell.execute_reply":"2021-10-28T15:39:04.163316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"3. Setup `CONFIG`\n\nMensetup varible - variable yang digunakan sebagai config pada notebook ini","metadata":{}},{"cell_type":"code","source":"SEED = 2021\nSIZE = (256, 256)\nBATCH_SIZE = 32\nFACE_THRESHOLD = 0.85\nFACE_DETECTOR = MTCNN()","metadata":{"execution":{"iopub.status.busy":"2021-10-28T15:39:06.413174Z","iopub.execute_input":"2021-10-28T15:39:06.413762Z","iopub.status.idle":"2021-10-28T15:39:08.97276Z","shell.execute_reply.started":"2021-10-28T15:39:06.413722Z","shell.execute_reply":"2021-10-28T15:39:08.972033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(\"../input/bdc-2021/train.csv\")\ntest = pd.read_csv(\"../input/bdc-2021/submission.csv\")\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-28T16:10:43.966097Z","iopub.execute_input":"2021-10-28T16:10:43.966715Z","iopub.status.idle":"2021-10-28T16:10:43.988007Z","shell.execute_reply.started":"2021-10-28T16:10:43.96667Z","shell.execute_reply":"2021-10-28T16:10:43.987293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images = []\nlabels = []\ntest_images = []\n\nTRAIN_DIR = \"../input/bdc-2021/Training\"\nTEST_DIR = \"../input/bdc-2021/Testing\"\n\nfor no, label in train[[\"nomor\", \"jenis kelamin\"]].values:\n    TEMP_DIR = os.path.join(TRAIN_DIR, str(no))\n    for file in os.listdir(TEMP_DIR):\n        file_dir = os.path.join(TEMP_DIR, file)\n        if \".ini\" not in file_dir:\n            images.append(file_dir)\n            labels.append(label)\n\nfor no in test.id.values:\n    file_dir = os.path.join(TEST_DIR, f\"{no}.jpg\")\n    if os.path.isfile(file_dir):\n        test_images.append(file_dir)\n    else:\n        test_images.append(None)\n        print(file_dir)","metadata":{"execution":{"iopub.status.busy":"2021-10-28T15:39:12.664708Z","iopub.execute_input":"2021-10-28T15:39:12.665341Z","iopub.status.idle":"2021-10-28T15:39:16.043309Z","shell.execute_reply.started":"2021-10-28T15:39:12.665294Z","shell.execute_reply":"2021-10-28T15:39:16.042552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(5, 5))\nsns.countplot(x=labels)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-28T15:39:16.045951Z","iopub.execute_input":"2021-10-28T15:39:16.046392Z","iopub.status.idle":"2021-10-28T15:39:16.230346Z","shell.execute_reply.started":"2021-10-28T15:39:16.046352Z","shell.execute_reply":"2021-10-28T15:39:16.229663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def read(path):\n    \"\"\"\n    Read data gambar\n    \"\"\"\n    img = Image.open(path)\n    return img\n\ndef show_images(list_dir, label = None, load_image = read, seed = SEED):\n    \"\"\"\n    Menampilkan Gambar Secara acak sebanyak 5 buah.\n    \"\"\"\n    random.seed(seed)\n    unique = [\"init\"]\n    if label:\n        unique = list(set(label))\n    fig, axes = plt.subplots(len(unique), 5, figsize = (20, 5 * len(unique)))\n    for i in range(len(unique)):\n        if i == 0 and unique[i] == \"init\":\n            data = random.sample(list_dir, 5)\n        else:\n            data = random.sample([x for x in zip(list_dir, label) if x[1] == unique[i]], 5)\n        for j in range(5):\n            if unique[0] != \"init\":\n                img = load_image(data[j][0])\n                axes[i, j].imshow(img)\n                axes[i, j].set_title(f'Label : {data[j][1]}', fontsize = 14)\n                axes[i, j].axis('off')\n            else:\n                img = load_image(data[j])\n                axes[j].imshow(img)\n                axes[j].axis('off')\n    fig.tight_layout()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-28T15:39:18.745919Z","iopub.execute_input":"2021-10-28T15:39:18.746616Z","iopub.status.idle":"2021-10-28T15:39:18.756695Z","shell.execute_reply.started":"2021-10-28T15:39:18.746579Z","shell.execute_reply":"2021-10-28T15:39:18.756002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_images(images, labels, seed=20)","metadata":{"execution":{"iopub.status.busy":"2021-10-28T15:39:20.09381Z","iopub.execute_input":"2021-10-28T15:39:20.09463Z","iopub.status.idle":"2021-10-28T15:39:22.813399Z","shell.execute_reply.started":"2021-10-28T15:39:20.094567Z","shell.execute_reply":"2021-10-28T15:39:22.812552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_faces(path):\n    image = cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2RGB)\n    faces = FACE_DETECTOR.detect_faces(image)\n    return faces\n\ndef load_and_preprocess_image(path: str, size = SIZE):\n    \"\"\"\n    Load & Preprocess data gambar\n    \"\"\"\n    image = img_to_array(load_img(path))\n    faces = [x['box'] for x in get_faces(path) if x['confidence'] > FACE_THRESHOLD]\n    if len(faces) > 0:\n        x, y, w, h = faces[0]\n        image = image[y:y+h, x:x+w]\n    img = tf.convert_to_tensor(image, dtype=tf.float32)\n    if len(faces) == 0:\n        shapes = tf.shape(img)\n        h, w = shapes[-3], shapes[-2]\n        dim = tf.minimum(h, w)\n        img = tf.image.resize_with_crop_or_pad(img, dim, dim)\n    img = tf.image.resize(img, size)\n    img = tf.cast(img, tf.float32) / 255.0\n    return img.numpy()","metadata":{"execution":{"iopub.status.busy":"2021-10-28T15:39:31.524677Z","iopub.execute_input":"2021-10-28T15:39:31.52516Z","iopub.status.idle":"2021-10-28T15:39:31.534842Z","shell.execute_reply.started":"2021-10-28T15:39:31.525121Z","shell.execute_reply":"2021-10-28T15:39:31.533013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_images(images, labels, load_image = load_and_preprocess_image, seed=20)","metadata":{"execution":{"iopub.status.busy":"2021-10-28T15:39:35.182019Z","iopub.execute_input":"2021-10-28T15:39:35.18231Z","iopub.status.idle":"2021-10-28T15:39:57.528272Z","shell.execute_reply.started":"2021-10-28T15:39:35.182273Z","shell.execute_reply":"2021-10-28T15:39:57.52751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def image_preprocessing(new_dir, images, labels=None):\n    if os.path.isdir(new_dir):\n        !rm -rf {new_dir}\n    os.mkdir(new_dir)\n    \n    new_images, new_labels = [], []\n    if not labels:\n        labels = [None for _ in range(len(images))]\n    \n    for path, label in tqdm(zip(images, labels), total=len(images)):\n        image = img_to_array(load_img(path))\n        faces = [x['box'] for x in sorted(get_faces(path), key=lambda x: x['confidence'], \n                                          reverse=True) if x['confidence'] > FACE_THRESHOLD]\n        if len(faces) > 0:\n            if label:\n                for j, (x, y, w, h) in enumerate(faces):\n                    img = image[y:y+h, x:x+w]\n                    img = tf.convert_to_tensor(img, dtype=tf.float32)\n                    img = tf.image.resize(img, SIZE)\n\n                    img_dir = os.path.join(new_dir, f'{j}_{path.split(\"/\")[-1]}')\n                    new_images.append(img_dir)\n                    new_labels.append(label)\n                    tf.keras.preprocessing.image.save_img(img_dir, img)\n            else:\n                x, y, w, h = faces[0]\n                img = image[y:y+h, x:x+w]\n                img = tf.convert_to_tensor(img, dtype=tf.float32)\n                img = tf.image.resize(img, SIZE)\n                \n                img_dir = os.path.join(new_dir, path.split('/')[-1])\n                new_images.append(img_dir)\n                new_labels.append(label)\n                tf.keras.preprocessing.image.save_img(img_dir, img)\n        else :\n            img = tf.convert_to_tensor(image, dtype=tf.float32)\n            shapes = tf.shape(img)\n            h, w = shapes[-3], shapes[-2]\n            dim = tf.minimum(h, w)\n            img = tf.image.resize_with_crop_or_pad(img, dim, dim)\n            img = tf.image.resize(img, SIZE)\n\n            img_dir = os.path.join(new_dir, path.split('/')[-1])\n            new_images.append(img_dir)\n            new_labels.append(label)\n            tf.keras.preprocessing.image.save_img(img_dir, img)\n    \n    return new_images, new_labels","metadata":{"execution":{"iopub.status.busy":"2021-10-28T15:45:21.880165Z","iopub.execute_input":"2021-10-28T15:45:21.880672Z","iopub.status.idle":"2021-10-28T15:45:21.904461Z","shell.execute_reply.started":"2021-10-28T15:45:21.880627Z","shell.execute_reply":"2021-10-28T15:45:21.903106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# new_train_dir = \"./train\"\n# new_test_dir = \"./test\"\n\n# new_images, new_labels = image_preprocessing(new_train_dir, images, labels)\n# new_test_images, _ = image_preprocessing(new_test_dir, test_images)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preprocessed = pd.read_csv(\"../input/bdc-2021/preprocessed/preprocessed.csv\")\npreprocessed.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-28T15:45:51.260693Z","iopub.execute_input":"2021-10-28T15:45:51.260952Z","iopub.status.idle":"2021-10-28T15:45:51.285168Z","shell.execute_reply.started":"2021-10-28T15:45:51.260924Z","shell.execute_reply":"2021-10-28T15:45:51.284513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preprocessed_dir = \"../input/bdc-2021/preprocessed\"\nnew_images = [os.path.join(preprocessed_dir, x) for x in preprocessed.image.values]\nnew_labels = preprocessed.label.values\nnew_test_images = [os.path.join(preprocessed_dir, \"test\", f\"{x}.jpg\") for x in test.id.values]","metadata":{"execution":{"iopub.status.busy":"2021-10-28T15:46:11.83955Z","iopub.execute_input":"2021-10-28T15:46:11.840281Z","iopub.status.idle":"2021-10-28T15:46:11.853121Z","shell.execute_reply.started":"2021-10-28T15:46:11.840241Z","shell.execute_reply":"2021-10-28T15:46:11.852361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# TO BE DELETED\nrancu = [\n    \"0db77c32-10cc-4595-84e6-90c37678f518\",\n    \"4870d63f-c2bb-4798-8e96-3bc9e6d0d8f4\",\n    \"3d6171d7-d21c-45fd-9f68-7945a79f4737\",\n    \"5e2e3f87-ce6f-4fbe-a6c9-c058796858dc\",\n    \"0bf9b43e-fd13-4ef9-b423-5a3d43fec20f\",\n]\nrancu = [os.path.join(TEST_DIR, f\"{x}.jpg\") for x in rancu]\nshow_images(rancu, load_image = load_and_preprocess_image)","metadata":{"execution":{"iopub.status.busy":"2021-10-28T15:43:32.574918Z","iopub.execute_input":"2021-10-28T15:43:32.575566Z","iopub.status.idle":"2021-10-28T15:43:39.426123Z","shell.execute_reply.started":"2021-10-28T15:43:32.575528Z","shell.execute_reply":"2021-10-28T15:43:39.425497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train, x_valid, y_train, y_valid = train_test_split(new_images, new_labels, test_size=0.15, \n                                                      stratify=new_labels, random_state=SEED)","metadata":{"execution":{"iopub.status.busy":"2021-10-28T15:46:16.108725Z","iopub.execute_input":"2021-10-28T15:46:16.109277Z","iopub.status.idle":"2021-10-28T15:46:16.120843Z","shell.execute_reply.started":"2021-10-28T15:46:16.109239Z","shell.execute_reply":"2021-10-28T15:46:16.119934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def decode_image(filename, label=None, image_size=SIZE):\n    \"\"\"\n    Decode Image from String Path Tensor\n    \"\"\"\n    bits = tf.io.read_file(filename)\n    image = tf.image.decode_jpeg(bits, channels=3)\n    image = tf.cast(image, tf.float32) / 255.0\n    image = tf.image.resize(image, SIZE)\n\n    if label is None: # if test\n        return image\n    else:\n        return image, label","metadata":{"execution":{"iopub.status.busy":"2021-10-28T15:46:50.735131Z","iopub.execute_input":"2021-10-28T15:46:50.735393Z","iopub.status.idle":"2021-10-28T15:46:50.741163Z","shell.execute_reply.started":"2021-10-28T15:46:50.735363Z","shell.execute_reply":"2021-10-28T15:46:50.740349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices((x_train, y_train))\n    .map(decode_image)\n    .cache()\n    .repeat()\n    .shuffle(1024)\n    .batch(BATCH_SIZE)\n)\n\n# TF Valid Dataset\nvalid_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices((x_valid, y_valid))\n    .map(decode_image)\n    .batch(BATCH_SIZE)\n    .cache()\n)\n\n# TF Test Dataset\ntest_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices((new_test_images))\n    .map(decode_image)\n    .batch(BATCH_SIZE)\n)","metadata":{"execution":{"iopub.status.busy":"2021-10-28T16:01:45.150976Z","iopub.execute_input":"2021-10-28T16:01:45.151714Z","iopub.status.idle":"2021-10-28T16:01:45.283754Z","shell.execute_reply.started":"2021-10-28T16:01:45.151666Z","shell.execute_reply":"2021-10-28T16:01:45.282977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.keras.backend.clear_session()\n\nmodel = tf.keras.Sequential([\n    tf.keras.applications.resnet50.ResNet50(\n        include_top=False, weights=None, input_shape = (256,256,3)),\n    tf.keras.layers.GlobalAveragePooling2D(),\n    tf.keras.layers.Dropout(0.5),\n    tf.keras.layers.Dense(1024, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(5e-4)),\n    tf.keras.layers.Dropout(0.5),\n    tf.keras.layers.Dense(1, activation='sigmoid'),\n])\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-10-28T15:46:57.09276Z","iopub.execute_input":"2021-10-28T15:46:57.093476Z","iopub.status.idle":"2021-10-28T15:46:58.365334Z","shell.execute_reply.started":"2021-10-28T15:46:57.093439Z","shell.execute_reply":"2021-10-28T15:46:58.364647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint = tf.keras.callbacks.ModelCheckpoint('Resnet50_best_model.h5', monitor='val_loss', \n                                                save_best_only=True, save_weights_only=True, \n                                                mode='min')\nmodel.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\nhistory = model.fit(train_dataset, epochs=50, validation_data=valid_dataset, \n          steps_per_epoch=len(x_train) // BATCH_SIZE,\n          callbacks = [checkpoint])","metadata":{"execution":{"iopub.status.busy":"2021-10-28T15:47:03.878946Z","iopub.execute_input":"2021-10-28T15:47:03.879791Z","iopub.status.idle":"2021-10-28T16:00:35.599749Z","shell.execute_reply.started":"2021-10-28T15:47:03.879737Z","shell.execute_reply":"2021-10-28T16:00:35.598967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(2, 1, figsize = (12, 10))\nax1.plot(range(1, len(history.history['loss']) + 1), history.history['loss'], label = 'loss')\nax1.plot(range(1, len(history.history['loss']) + 1), history.history['val_loss'], label = 'val_loss')\nax1.set_title('Loss at Training', fontsize = 14)\nax1.legend()\nax2.plot(range(1, len(history.history['loss']) + 1), history.history['accuracy'], label = 'accuracy')\nax2.plot(range(1, len(history.history['loss']) + 1), history.history['val_accuracy'], label = 'val_accuracy')\nax2.set_title('Accuracy at Training', fontsize = 14)\nax2.legend()\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-28T16:00:45.698192Z","iopub.execute_input":"2021-10-28T16:00:45.698465Z","iopub.status.idle":"2021-10-28T16:00:46.081726Z","shell.execute_reply.started":"2021-10-28T16:00:45.698436Z","shell.execute_reply":"2021-10-28T16:00:46.081035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_weights('Resnet50_best_model.h5')","metadata":{"execution":{"iopub.status.busy":"2021-10-28T16:01:06.74345Z","iopub.execute_input":"2021-10-28T16:01:06.744076Z","iopub.status.idle":"2021-10-28T16:01:07.025426Z","shell.execute_reply.started":"2021-10-28T16:01:06.744034Z","shell.execute_reply":"2021-10-28T16:01:07.024675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_pred_classes = np.array(model.predict(valid_dataset).flatten() >= .5, dtype = 'int')\nprint(f'Accuracy Valid Data : {accuracy_score(y_valid, val_pred_classes)}')\nprint(f'F1 Score Valid Data : {f1_score(y_valid, val_pred_classes)}')","metadata":{"execution":{"iopub.status.busy":"2021-10-28T16:01:08.683727Z","iopub.execute_input":"2021-10-28T16:01:08.684077Z","iopub.status.idle":"2021-10-28T16:01:10.257077Z","shell.execute_reply.started":"2021-10-28T16:01:08.684036Z","shell.execute_reply":"2021-10-28T16:01:10.256309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (7, 7))\nsns.heatmap(confusion_matrix(y_valid, val_pred_classes, normalize = 'true'),\n            annot=True, cmap=plt.cm.Blues)\nplt.title('Normalized Confussion Matrix Valid Data')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-28T16:01:17.732798Z","iopub.execute_input":"2021-10-28T16:01:17.733434Z","iopub.status.idle":"2021-10-28T16:01:17.971127Z","shell.execute_reply.started":"2021-10-28T16:01:17.733394Z","shell.execute_reply":"2021-10-28T16:01:17.970425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame({'id' :[x.split('/')[-1].split('.')[0] for x in new_test_images],\n                           'jenis kelamin': np.array(model.predict(test_dataset).flatten() >= .5, dtype = 'int')})\ntest = test.merge(submission, on=\"id\")\ntest.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-28T16:10:54.32584Z","iopub.execute_input":"2021-10-28T16:10:54.326485Z","iopub.status.idle":"2021-10-28T16:10:56.300166Z","shell.execute_reply.started":"2021-10-28T16:10:54.326444Z","shell.execute_reply":"2021-10-28T16:10:56.299487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-10-28T16:11:41.152149Z","iopub.execute_input":"2021-10-28T16:11:41.152416Z","iopub.status.idle":"2021-10-28T16:11:41.161938Z","shell.execute_reply.started":"2021-10-28T16:11:41.152387Z","shell.execute_reply":"2021-10-28T16:11:41.161127Z"},"trusted":true},"execution_count":null,"outputs":[]}]}