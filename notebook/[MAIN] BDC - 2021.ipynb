{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# BDC - Satria Data 2021\n\nTask : Gender Detection\n\n## Authors\n\n1. Muhammad Amanda\n2. Naufal Zhafran A.\n3. Wahyu Setianto\n\n## Running On\n\nKaggle [using GPU]","metadata":{}},{"cell_type":"markdown","source":"## First Thing First\n\nMenginstall library yang diperlukan dan mengimport library - library yang akan digunakan serta menseting variable config yang akan digunakan di dalam notebook ini.","metadata":{}},{"cell_type":"markdown","source":"1. Menginstal library`MTCNN`\n\nLibrary `MTCNN` adalah library yang digunakan untuk preprocessing data gambar pada notebook ini","metadata":{}},{"cell_type":"code","source":"!pip -q install mtcnn","metadata":{"execution":{"iopub.status.busy":"2021-10-30T15:58:50.773839Z","iopub.execute_input":"2021-10-30T15:58:50.77418Z","iopub.status.idle":"2021-10-30T15:58:59.990545Z","shell.execute_reply.started":"2021-10-30T15:58:50.774101Z","shell.execute_reply":"2021-10-30T15:58:59.989702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"2. Importing library\n\nMengimport library yang akan digunakan dalam notebook ini.","metadata":{}},{"cell_type":"code","source":"# Umum\nimport os, random, re\nfrom tqdm.notebook import tqdm\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\n\n# Tensorflow\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\n\n# Metrics & Splitting data\nfrom sklearn.metrics import *\nfrom sklearn.model_selection import *\n\n# Plotting\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Preprocessing\nimport cv2\nfrom mtcnn import MTCNN\nimport albumentations as A\n\nprint(\"Tensorflow :\", tf.__version__)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-30T15:58:59.993533Z","iopub.execute_input":"2021-10-30T15:58:59.993825Z","iopub.status.idle":"2021-10-30T15:59:05.85544Z","shell.execute_reply.started":"2021-10-30T15:58:59.993789Z","shell.execute_reply":"2021-10-30T15:59:05.854695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"3. Setup `CONFIG`\n\nMensetup varible - variable yang digunakan sebagai config pada notebook ini","metadata":{}},{"cell_type":"code","source":"SEED = 2021\nSIZE = (200, 200)\nBATCH_SIZE = 32\nFACE_THRESHOLD = 0.95\nFACE_DETECTOR = MTCNN()","metadata":{"execution":{"iopub.status.busy":"2021-10-30T15:59:05.856825Z","iopub.execute_input":"2021-10-30T15:59:05.857403Z","iopub.status.idle":"2021-10-30T15:59:08.322716Z","shell.execute_reply.started":"2021-10-30T15:59:05.857361Z","shell.execute_reply":"2021-10-30T15:59:08.322017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataset\n\nLoad dataset yang mengandung informasi `path` dari data gambar","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv(\"../input/bdc-2021/train.csv\")\ntest = pd.read_csv(\"../input/bdc-2021/submission.csv\")\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-30T15:59:08.32474Z","iopub.execute_input":"2021-10-30T15:59:08.324962Z","iopub.status.idle":"2021-10-30T15:59:08.372287Z","shell.execute_reply.started":"2021-10-30T15:59:08.324936Z","shell.execute_reply":"2021-10-30T15:59:08.371625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"memperjelas `path` ke setiap data gambar","metadata":{}},{"cell_type":"code","source":"images = []\nlabels = []\ntest_images = []\n\nTRAIN_DIR = \"../input/bdc-2021/Training\"\nTEST_DIR = \"../input/bdc-2021/Testing\"\n\nfor no, label in train[[\"nomor\", \"jenis kelamin\"]].values:\n    TEMP_DIR = os.path.join(TRAIN_DIR, str(no))\n    for file in os.listdir(TEMP_DIR):\n        file_dir = os.path.join(TEMP_DIR, file)\n        if \".ini\" not in file_dir:\n            images.append(file_dir)\n            labels.append(label)\n\nfor no in test.id.values:\n    file_dir = os.path.join(TEST_DIR, f\"{no}.jpg\")\n    if os.path.isfile(file_dir):\n        test_images.append(file_dir)\n    else:\n        test_images.append(None)\n        print(file_dir)","metadata":{"execution":{"iopub.status.busy":"2021-10-30T15:59:08.373601Z","iopub.execute_input":"2021-10-30T15:59:08.373854Z","iopub.status.idle":"2021-10-30T15:59:14.166704Z","shell.execute_reply.started":"2021-10-30T15:59:08.373821Z","shell.execute_reply":"2021-10-30T15:59:14.165953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"menampilkan dan mengecek beberapa gambar pada data `train`","metadata":{}},{"cell_type":"code","source":"def read(path):\n    \"\"\"\n    Read data gambar\n    \"\"\"\n    img = Image.open(path)\n    return img\n\ndef show_images(list_dir, label = None, load_image = read, seed = SEED):\n    \"\"\"\n    Menampilkan Gambar Secara acak sebanyak 5 buah.\n    \"\"\"\n    random.seed(seed)\n    unique = [\"init\"]\n    if label:\n        unique = list(set(label))\n    fig, axes = plt.subplots(len(unique), 5, figsize = (20, 5 * len(unique)))\n    for i in range(len(unique)):\n        if i == 0 and unique[i] == \"init\":\n            data = random.sample(list_dir, 5)\n        else:\n            data = random.sample([x for x in zip(list_dir, label) if x[1] == unique[i]], 5)\n        for j in range(5):\n            if unique[0] != \"init\":\n                img = load_image(data[j][0])\n                axes[i, j].imshow(img)\n                axes[i, j].set_title(f'Label : {data[j][1]}', fontsize = 14)\n                axes[i, j].axis('off')\n            else:\n                img = load_image(data[j])\n                axes[j].imshow(img)\n                axes[j].axis('off')\n    fig.tight_layout()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-30T15:59:14.17116Z","iopub.execute_input":"2021-10-30T15:59:14.173068Z","iopub.status.idle":"2021-10-30T15:59:14.187951Z","shell.execute_reply.started":"2021-10-30T15:59:14.173028Z","shell.execute_reply":"2021-10-30T15:59:14.187136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_images(images, labels, seed=20)","metadata":{"execution":{"iopub.status.busy":"2021-10-30T15:59:14.192883Z","iopub.execute_input":"2021-10-30T15:59:14.195641Z","iopub.status.idle":"2021-10-30T15:59:16.686972Z","shell.execute_reply.started":"2021-10-30T15:59:14.195497Z","shell.execute_reply":"2021-10-30T15:59:16.684831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preprocess Data\n\nMetode yang digunakan:\n\n1. Mengekstrak wajah - wajah yang terdapat pada gambar menjadi gambar - gambar baru dengan label yang sama dengan menggunakan model `MTCNN`\n2. Pada data test jika terdapat dua wajah yang terdeteksi pada satu gambar akan di ambil wajah dengan tingkat confidence terbesar yang diberikan oleh model `MTCNN`.\n3. Jika tidak terdetect wajah pada salah satu gambar maka akan dilakukan crop pada bagian tengah gambar sehingga gambar berbentuk persegi atau `jxj` pixel.\n4. Selanjutnya gambar akan di resize menjadi ukuran `256x256` pixel\n\nberikut adalah contoh hasil preprocess data gambar.","metadata":{}},{"cell_type":"code","source":"def get_faces(path):\n    image = cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2RGB)\n    faces = FACE_DETECTOR.detect_faces(image)\n    return faces\n\ndef load_and_preprocess_image(path: str, size = SIZE):\n    \"\"\"\n    Load & Preprocess data gambar\n    \"\"\"\n    image = img_to_array(load_img(path))\n    faces = [x['box'] for x in get_faces(path) if x['confidence'] > FACE_THRESHOLD]\n    if len(faces) > 0:\n        x, y, w, h = faces[0]\n        image = image[y:y+h, x:x+w]\n    img = tf.convert_to_tensor(image, dtype=tf.float32)\n    if len(faces) == 0:\n        shapes = tf.shape(img)\n        h, w = shapes[-3], shapes[-2]\n        dim = tf.minimum(h, w)\n        img = tf.image.resize_with_crop_or_pad(img, dim, dim)\n    img = tf.image.resize(img, size)\n    img = tf.cast(img, tf.float32) / 255.0\n    return img.numpy()","metadata":{"execution":{"iopub.status.busy":"2021-10-30T15:59:16.687974Z","iopub.execute_input":"2021-10-30T15:59:16.688203Z","iopub.status.idle":"2021-10-30T15:59:16.700109Z","shell.execute_reply.started":"2021-10-30T15:59:16.688172Z","shell.execute_reply":"2021-10-30T15:59:16.699186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_images(images, labels, load_image = load_and_preprocess_image, seed=20)","metadata":{"execution":{"iopub.status.busy":"2021-10-30T15:59:16.702224Z","iopub.execute_input":"2021-10-30T15:59:16.702829Z","iopub.status.idle":"2021-10-30T15:59:38.428264Z","shell.execute_reply.started":"2021-10-30T15:59:16.702724Z","shell.execute_reply":"2021-10-30T15:59:38.427607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Augmentasi Data\n\nMelakukan augmentasi untuk memperbanyak data. Metode augmentasi yang digunakan yaitu:\n\n1. Horizontal flip\n2. Donwscale kualitas gambar\n3. Random rotate dengan rentang -30 sampai 30 derajad\n4. Shift, scale, dan rotate gambar\n5. Blur\n6. Random brightness","metadata":{}},{"cell_type":"code","source":"aug = A.Compose([\n    A.HorizontalFlip(p=0.4),\n    A.Downscale(scale_min=0.6, scale_max=0.9, p=0.3),\n    A.Rotate(limit=(-30,30), p=0.6),\n    A.ShiftScaleRotate(shift_limit=(-0.07, 0.07), scale_limit=(-0.05, 0.1), rotate_limit=(-15, 15), p=0.4),\n    A.OneOf([\n        A.MotionBlur(p=.4),\n        A.MedianBlur(blur_limit=3, p=0.4),\n        A.Blur(blur_limit=3, p=0.4),\n    ], p=0.4),\n    A.RandomBrightnessContrast(brightness_limit=(-0.25, 0.15), p=0.4),\n])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def visualize_aug(path):\n    fig, axes = plt.subplots(1, 5, figsize = (20, 5))\n    image = load_and_preprocess_image(path)\n    axes[0].imshow(image)\n    axes[0].axis('off')\n    for i in range(1, 5):\n        augmented = aug(image=image)['image']\n        axes[i].imshow(augmented)\n        axes[i].axis('off')\n    fig.tight_layout()\n    plt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"random.seed(SEED)\nfor i in range(3):\n    visualize_aug(images[i])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Running preprocessing pada data gambar secara keseluruhan","metadata":{}},{"cell_type":"code","source":"def image_preprocessing(new_dir, images, labels=None):\n    if os.path.isdir(new_dir):\n        !rm -rf {new_dir}\n    os.mkdir(new_dir)\n    \n    new_images, new_labels = [], []\n    if not labels:\n        labels = [None for _ in range(len(images))]\n    \n    for path, label in tqdm(zip(images, labels), total=len(images)):\n        image = img_to_array(load_img(path))\n        if label != None:\n            faces = [x['box'] for x in sorted(get_faces(path), key=lambda x: x['confidence'], \n                                              reverse=True) if x['confidence'] > FACE_THRESHOLD]\n        else:\n            faces = [x['box'] for x in sorted(get_faces(path), key=lambda x: x['confidence'], reverse=True)]\n        if len(faces) > 0:\n            if label != None:\n                for j, (x, y, w, h) in enumerate(faces):\n                    img = image[y:y+h, x:x+w]\n                    img = tf.convert_to_tensor(img, dtype=tf.float32)\n                    img = tf.image.resize(img, SIZE)\n                    img = tf.cast(img, tf.float32) / 255.0\n\n                    img_dir = os.path.join(new_dir, f'{j}_{path.split(\"/\")[-1]}')\n                    new_images.append(img_dir)\n                    new_labels.append(label)\n                    tf.keras.preprocessing.image.save_img(img_dir, img)\n                    \n                    for k in range(3):\n                        augmented = aug(image=img.numpy())['image']\n                        img_dir = os.path.join(new_dir, f'aug-{k}_{j}_{path.split(\"/\")[-1]}')\n                        new_images.append(img_dir)\n                        new_labels.append(label)\n                        tf.keras.preprocessing.image.save_img(img_dir, augmented)\n            else:\n                x, y, w, h = faces[0]\n                img = image[y:y+h, x:x+w]\n                img = tf.convert_to_tensor(img, dtype=tf.float32)\n                img = tf.image.resize(img, SIZE)\n                img = tf.cast(img, tf.float32) / 255.0\n                \n                img_dir = os.path.join(new_dir, path.split('/')[-1])\n                new_images.append(img_dir)\n                new_labels.append(label)\n                tf.keras.preprocessing.image.save_img(img_dir, img)\n        else :\n            img = tf.convert_to_tensor(image, dtype=tf.float32)\n            shapes = tf.shape(img)\n            h, w = shapes[-3], shapes[-2]\n            dim = tf.minimum(h, w)\n            img = tf.image.resize_with_crop_or_pad(img, dim, dim)\n            img = tf.image.resize(img, SIZE)\n            img = tf.cast(img, tf.float32) / 255.0\n\n            img_dir = os.path.join(new_dir, path.split('/')[-1])\n            new_images.append(img_dir)\n            new_labels.append(label)\n            tf.keras.preprocessing.image.save_img(img_dir, img)\n            \n            if label != None:\n                for k in range(3):\n                    augmented = aug(image=img.numpy())['image']\n                    img_dir = os.path.join(new_dir,  f'aug-{k}_{path.split(\"/\")[-1]}')\n                    new_images.append(img_dir)\n                    new_labels.append(label)\n                    tf.keras.preprocessing.image.save_img(img_dir, augmented)\n    \n    return new_images, new_labels","metadata":{"execution":{"iopub.status.busy":"2021-10-30T15:59:38.430907Z","iopub.execute_input":"2021-10-30T15:59:38.431294Z","iopub.status.idle":"2021-10-30T15:59:38.461052Z","shell.execute_reply.started":"2021-10-30T15:59:38.431259Z","shell.execute_reply":"2021-10-30T15:59:38.460459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Untuk menghemat waktu running akan di skip bagian ini dan di ganti dengan meload data hasil preprocess yang sudah di save pada run sebelumnya. Namun jika ingin melakukan preprocess pada run sekarang maka uncomment code di bawah ini.\n\n**Peringatan** : running block code di bawah memakan waktu sekitar 50 menit dengan GPU Nvidia Tesla P100-PCIE.","metadata":{}},{"cell_type":"code","source":"# new_train_dir = \"./train\"\n# new_test_dir = \"./test\"\n\n# random.seed(SEED)\n# new_images, new_labels = image_preprocessing(new_train_dir, images, labels)\n# new_test_images, _ = image_preprocessing(new_test_dir, test_images)","metadata":{"execution":{"iopub.status.busy":"2021-10-30T15:59:38.463435Z","iopub.execute_input":"2021-10-30T15:59:38.463859Z","iopub.status.idle":"2021-10-30T15:59:38.487386Z","shell.execute_reply.started":"2021-10-30T15:59:38.463812Z","shell.execute_reply":"2021-10-30T15:59:38.486678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Note** : Comment dua block kode di bawah jika melakukan preprocess pada run saat ini.","metadata":{}},{"cell_type":"code","source":"preprocessed = pd.read_csv(\"../input/bdc-2021/preprocessed-augmented/preprocessed.csv\")\npreprocessed.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-30T15:59:38.488863Z","iopub.execute_input":"2021-10-30T15:59:38.489343Z","iopub.status.idle":"2021-10-30T15:59:38.534447Z","shell.execute_reply.started":"2021-10-30T15:59:38.489304Z","shell.execute_reply":"2021-10-30T15:59:38.533622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!wget https://raw.githubusercontent.com/Hyuto/fun/master/excluded.txt\n    \nwith open(\"./excluded.txt\") as f:\n    excluded = f.read().split(\"\\n\")\n    \npatterns = fr'{\"|\".join(excluded)}'","metadata":{"execution":{"iopub.status.busy":"2021-10-30T15:59:38.535831Z","iopub.execute_input":"2021-10-30T15:59:38.53669Z","iopub.status.idle":"2021-10-30T15:59:39.44927Z","shell.execute_reply.started":"2021-10-30T15:59:38.53665Z","shell.execute_reply":"2021-10-30T15:59:39.448369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preprocessed_dir = \"../input/bdc-2021/preprocessed-augmented\"\nnew_images, new_labels = [], []\n\nfor image, label in preprocessed[[\"image\", \"label\"]].values:\n    if not re.search(patterns, image):\n        new_images.append(os.path.join(preprocessed_dir, image))\n        new_labels.append(label)\n\nnew_test_images = np.asarray([os.path.join(preprocessed_dir, \"test\", f\"{x}.jpg\") for x in test.id.values])\n\nnew_images = np.asarray(new_images)\nnew_labels = np.asarray(new_labels)","metadata":{"execution":{"iopub.status.busy":"2021-10-30T15:59:39.451196Z","iopub.execute_input":"2021-10-30T15:59:39.451462Z","iopub.status.idle":"2021-10-30T15:59:39.671203Z","shell.execute_reply.started":"2021-10-30T15:59:39.451422Z","shell.execute_reply":"2021-10-30T15:59:39.670472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Mengecek distribusi label pada data","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(5, 5))\nsns.countplot(x=new_labels)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-30T15:59:39.672676Z","iopub.execute_input":"2021-10-30T15:59:39.672963Z","iopub.status.idle":"2021-10-30T15:59:39.832161Z","shell.execute_reply.started":"2021-10-30T15:59:39.672926Z","shell.execute_reply":"2021-10-30T15:59:39.831436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Jumlah data yang berlabel `0` dan `1` cenderung sama.","metadata":{}},{"cell_type":"markdown","source":"**Splitting Data**\n\nSplit data train menjadi data `train` dan data `valid` dengan proporsi `85:15`","metadata":{}},{"cell_type":"code","source":"x_train, x_valid, y_train, y_valid = train_test_split(new_images, new_labels, test_size=0.15, \n                                                      stratify=new_labels, random_state=SEED)","metadata":{"execution":{"iopub.status.busy":"2021-10-30T15:59:39.83642Z","iopub.execute_input":"2021-10-30T15:59:39.837079Z","iopub.status.idle":"2021-10-30T15:59:39.854028Z","shell.execute_reply.started":"2021-10-30T15:59:39.837038Z","shell.execute_reply":"2021-10-30T15:59:39.85338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Tensorflow Data**\n\nLoad data gambar menggunakan `Tensorflow Data` agar pada saat pelatihan model penggunaan memmori dapat lebih optimal","metadata":{}},{"cell_type":"code","source":"def decode_image(filename, label=None, image_size=SIZE):\n    \"\"\"\n    Decode Image from String Path Tensor\n    \"\"\"\n    bits = tf.io.read_file(filename)\n    image = tf.image.decode_jpeg(bits, channels=3)\n    image = tf.cast(image, tf.float32) / 255.0\n    image = tf.image.resize(image, SIZE)\n\n    if label is None: # if test\n        return image\n    else:\n        return image, label","metadata":{"execution":{"iopub.status.busy":"2021-10-30T15:59:39.855309Z","iopub.execute_input":"2021-10-30T15:59:39.855556Z","iopub.status.idle":"2021-10-30T15:59:39.861028Z","shell.execute_reply.started":"2021-10-30T15:59:39.855523Z","shell.execute_reply":"2021-10-30T15:59:39.860101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_model(kernel_s=(3,3)):\n    model = tf.keras.models.Sequential([\n        tf.keras.layers.Conv2D(32,kernel_s,activation='relu',input_shape=(200,200,3),\n                            kernel_regularizer=tf.keras.regularizers.l2(0.001),padding=\"VALID\"),\n        tf.keras.layers.MaxPooling2D((2,2)),\n        #tf.keras.layers.Dropout(0.2),\n        tf.keras.layers.Conv2D(64,kernel_s,activation='relu'),\n        tf.keras.layers.MaxPooling2D((2,2)),\n        #tf.keras.layers.Dropout(0.2),\n        tf.keras.layers.Conv2D(64,kernel_s,activation='relu'),\n        tf.keras.layers.MaxPooling2D((2,2)),\n        #tf.keras.layers.Dropout(0.2),\n        tf.keras.layers.Conv2D(128,kernel_s,activation='relu'),\n        tf.keras.layers.MaxPooling2D((2,2)),\n        #tf.keras.layers.Dropout(0.2),\n        tf.keras.layers.Conv2D(128,kernel_s,activation='relu'),\n        tf.keras.layers.MaxPooling2D((2,2)),\n        #tf.keras.layers.Dropout(0.2),\n        tf.keras.layers.Flatten(),\n        tf.keras.layers.Dense(256, activation='relu', \n                              kernel_regularizer=tf.keras.regularizers.l2(5e-4)),\n        tf.keras.layers.Dense(1, activation='sigmoid')\n    ])\n    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-10-30T16:00:02.770149Z","iopub.execute_input":"2021-10-30T16:00:02.770862Z","iopub.status.idle":"2021-10-30T16:00:02.781216Z","shell.execute_reply.started":"2021-10-30T16:00:02.770822Z","shell.execute_reply":"2021-10-30T16:00:02.780361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"split = 5\nprediksi = np.zeros((len(new_test_images), 1), dtype=np.float32)\nacc_scores, f1_scores = [], []\n\ntest_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices((new_test_images))\n    .map(decode_image)\n    .batch(BATCH_SIZE)\n)\n\ncv = StratifiedKFold(n_splits=split, shuffle=True, random_state=SEED)\nfor i, (train_index, test_index) in enumerate(cv.split(new_images, new_labels)):\n    tf.keras.backend.clear_session()\n    x_train, x_valid = new_images[train_index], new_images[test_index]\n    y_train, y_valid = new_labels[train_index], new_labels[test_index]\n\n    train_dataset = (\n        tf.data.Dataset\n        .from_tensor_slices((x_train, y_train))\n        .map(decode_image, num_parallel_calls=tf.data.AUTOTUNE)\n        .cache()\n        .repeat()\n        .shuffle(1024)\n        .batch(BATCH_SIZE)\n        .prefetch(tf.data.AUTOTUNE)\n    )\n    \n    valid_dataset = (\n        tf.data.Dataset\n        .from_tensor_slices((x_valid, y_valid))\n        .map(decode_image, num_parallel_calls=tf.data.AUTOTUNE)\n        .batch(BATCH_SIZE)\n        .cache()\n        .prefetch(tf.data.AUTOTUNE)\n    )\n\n    model = build_model()\n    checkpoint = tf.keras.callbacks.ModelCheckpoint(f'{i}_Resnet50_best_model.h5', monitor='val_accuracy', \n                                                save_best_only=True, save_weights_only=True, \n                                                mode='max')\n    print(f\"\\nCV {i+1}\")\n    model.fit(train_dataset, epochs=30, validation_data=valid_dataset, \n              steps_per_epoch=len(x_train) // BATCH_SIZE,\n              callbacks = [checkpoint])\n    model.load_weights(f'{i}_Resnet50_best_model.h5')\n    val_pred_classes = np.array(model.predict(valid_dataset).flatten() >= .5, dtype = 'int')\n    acc, f1 = accuracy_score(y_valid, val_pred_classes), f1_score(y_valid, val_pred_classes)\n\n    acc_scores.append(acc)\n    f1_scores.append(f1)\n    prediksi += model.predict(test_dataset)\n\n    del train_dataset\n    del valid_dataset","metadata":{"execution":{"iopub.status.busy":"2021-10-30T16:00:04.347098Z","iopub.execute_input":"2021-10-30T16:00:04.347527Z","iopub.status.idle":"2021-10-30T16:17:50.725355Z","shell.execute_reply.started":"2021-10-30T16:00:04.347482Z","shell.execute_reply":"2021-10-30T16:17:50.724585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(split):\n    print(f\"Split {i + 1} : {acc_scores[i]} acc - {f1_scores[i]} f1\")\n    \nprint(\"\\nMean Acc\", sum(acc_scores) / split)\nprint(\"Mean F1 \", sum(f1_scores) / split)","metadata":{"execution":{"iopub.status.busy":"2021-10-30T16:17:52.405807Z","iopub.execute_input":"2021-10-30T16:17:52.406075Z","iopub.status.idle":"2021-10-30T16:17:52.414194Z","shell.execute_reply.started":"2021-10-30T16:17:52.406047Z","shell.execute_reply":"2021-10-30T16:17:52.413421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Membuat Submission","metadata":{}},{"cell_type":"code","source":"submission = pd.DataFrame({'id' :[x.split('/')[-1].split('.')[0] for x in new_test_images],\n                           'jenis kelamin': np.array((prediksi / split).flatten() >= .5, dtype = 'int')})\ntest = test.merge(submission, on=\"id\")\ntest.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-30T16:18:12.943263Z","iopub.execute_input":"2021-10-30T16:18:12.943536Z","iopub.status.idle":"2021-10-30T16:18:12.969309Z","shell.execute_reply.started":"2021-10-30T16:18:12.943497Z","shell.execute_reply":"2021-10-30T16:18:12.968647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.to_csv(\"submission-1_1.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-10-30T16:18:23.44525Z","iopub.execute_input":"2021-10-30T16:18:23.445505Z","iopub.status.idle":"2021-10-30T16:18:23.460442Z","shell.execute_reply.started":"2021-10-30T16:18:23.445477Z","shell.execute_reply":"2021-10-30T16:18:23.459531Z"},"trusted":true},"execution_count":null,"outputs":[]}]}